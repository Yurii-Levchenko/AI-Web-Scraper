# üï∏Ô∏è AI Web Scraper

[![Streamlit App](https://img.shields.io/badge/Live%20App-Click%20Here-brightgreen?logo=streamlit)](https://ai-web-scraperrr.streamlit.app/)

**Live Demo:** [https://ai-web-scraperrr.streamlit.app/](https://ai-web-scraperrr.streamlit.app/)

An advanced, cloud-ready web scraping application with a modern Streamlit UI, Google OAuth authentication, and AI-powered content extraction using Selenium and large language models (LLMs).

---

## üöÄ Features

- **Streamlit Web Interface**  
  Intuitive, interactive UI for scraping and parsing any website.

- **Google OAuth Authentication**  
  Secure user login with Google, ready for public or private deployments.

- **Dynamic Content Scraping**  
  Uses Selenium with headless Firefox to handle JavaScript-heavy and dynamic sites.

- **AI-Powered Parsing**  
  Extracts and summarizes web content using LLMs (OpenAI or Ollama).

- **Cloud-Ready**  
  Deployable on Streamlit Community Cloud or any Linux server.

- **Stealth & Anti-Bot**  
  Randomized window size, custom user-agent, and simulated mouse movements to reduce bot detection.

---

## üõ†Ô∏è Tech Stack

- [Streamlit](https://streamlit.io/) ‚Äì UI and deployment
- [Selenium](https://www.selenium.dev/) ‚Äì Browser automation
- [webdriver-manager](https://pypi.org/project/webdriver-manager/) ‚Äì Automatic driver management
- [BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/) ‚Äì HTML parsing
- [OpenAI](https://platform.openai.com/) / [Ollama](https://ollama.com/) ‚Äì LLM-based content extraction
- [Google OAuth](https://developers.google.com/identity/protocols/oauth2) ‚Äì Authentication

---

## ‚ö° Quick Start

1. **Clone the repo**
   ```bash
   git clone https://github.com/yourusername/ai-web-scraper.git
   cd ai-web-scraper
   ```

2. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

3. **Set up secrets**
   - Add your `OPENAI_API_KEY` and (optionally) `GITHUB_TOKEN` to `.streamlit/secrets.toml`:
     ```toml
     OPENAI_API_KEY = "sk-..."
     GITHUB_TOKEN = "ghp-..."
     ```

4. **(For cloud) Add Firefox to packages.txt**
   ```
   firefox-esr
   ```

5. **Run the app**
   ```bash
   streamlit run main.py
   ```

---

## üåê Deployment

- **Streamlit Community Cloud:**  
  Push to GitHub and deploy directly.
- **Custom Server:**  
  Install Firefox and run as above.

---

## üìù Usage

1. **Log in with Google.**
2. **Enter a website URL** to scrape.
3. **Describe what you want to extract** (e.g., "List all main titles in a table").
4. **Choose AI backend** (OpenAI or Ollama).
5. **View and download results.**

---

## üß† Example Prompts

- "Extract all product names and prices."
- "Summarize the main news headlines."
- "List all links on the page."

---

## üõ°Ô∏è Disclaimer

- Use responsibly. Respect website terms of service and robots.txt.
- Some sites may block scraping from cloud IPs.

---

## üìÑ License

MIT License

---

## üôå Acknowledgements

- [Streamlit](https://streamlit.io/)
- [Selenium](https://www.selenium.dev/)
- [BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/)
- [OpenAI](https://platform.openai.com/)
- [Ollama](https://ollama.com/)
- [webdriver-manager](https://pypi.org/project/webdriver-manager/)

---

> **Made with ‚ù§Ô∏è by [Your Name]**